{
	"name": "dataflow_csv_to_json",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "adf_input_ds",
						"type": "DatasetReference"
					},
					"name": "ReadSourceData"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "Json_sink",
						"type": "DatasetReference"
					},
					"name": "ExportJson"
				}
			],
			"transformations": [
				{
					"name": "DerivedSourceSink"
				},
				{
					"name": "AggregateMappings"
				},
				{
					"name": "AppendTranslator"
				}
			],
			"script": "source(output(\n\t\tSOURCE_NAME as string,\n\t\tSOURCE_TYPE as string,\n\t\tSOURCE_PHYSICALTYPE as string,\n\t\tTARGET_NAME as string,\n\t\tTARGET_TYPE as string,\n\t\tTARGET_PHYSICALTYPE as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> ReadSourceData\nReadSourceData derive(subjson = @(source=@(name=SOURCE_NAME,\n\t\ttype=SOURCE_TYPE,\n\t\tphysicalType=SOURCE_PHYSICALTYPE),\n\t\tsink=@(name=TARGET_NAME,\n\t\ttype=TARGET_TYPE,\n\t\tphysicalType=TARGET_PHYSICALTYPE))) ~> DerivedSourceSink\nDerivedSourceSink aggregate(mappings = collect(subjson)) ~> AggregateMappings\nAggregateMappings derive(type = concat(\"TabularTranslator\"),\n\t\tmappings = mappings) ~> AppendTranslator\nAppendTranslator sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tmapColumn(\n\t\ttype,\n\t\tmappings\n\t)) ~> ExportJson"
		}
	}
}